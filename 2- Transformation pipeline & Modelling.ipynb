{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract files\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "if 'train.csv' not in os.listdir():\n",
    "    ZipFile('titanic.zip','r').extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n\n             SibSp  Parch     Ticket     Fare Cabin Embarked  \nPassengerId                                                   \n1                1      0  A/5 21171   7.2500   NaN        S  \n2                1      0   PC 17599  71.2833   C85        C  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "## Load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "display(df_train.head(2))\n",
    "X_train, y_train = df_train.loc[:, df_train.columns != 'Survived'], df_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.55097434, -0.50244517, -0.06821981,  0.0792407 , -0.57916179,\n",
       "       -0.83492139, -0.85024275,  0.05915988,  0.        ,  1.        ,\n",
       "        1.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "## Transformation pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TitlesAttribute(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.title_dictionary = {\n",
    "            \"Capt\": \"Officer\",\n",
    "            \"Col\": \"Officer\",\n",
    "            \"Major\": \"Officer\",\n",
    "            \"Jonkheer\": \"Royalty\",\n",
    "            \"Don\": \"Royalty\",\n",
    "            \"Sir\" : \"Royalty\",\n",
    "            \"Dr\": \"Officer\",\n",
    "            \"Rev\": \"Officer\",\n",
    "            \"the Countess\":\"Royalty\",\n",
    "            \"Mme\": \"Mrs\",\n",
    "            \"Mlle\": \"Miss\",\n",
    "            \"Ms\": \"Mrs\",\n",
    "            \"Mr\" : \"Mr\",\n",
    "            \"Mrs\" : \"Mrs\",\n",
    "            \"Miss\" : \"Miss\",\n",
    "            \"Master\" : \"Master\",\n",
    "            \"Lady\" : \"Royalty\"\n",
    "        }\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def get_titles(self, row):\n",
    "        try:\n",
    "            return self.title_dictionary[row['Name'].split(', ')[1].split('.')[0]]\n",
    "        except:\n",
    "            if row['Sex'] == 'male':\n",
    "                return \"Mr\"\n",
    "            else:\n",
    "                return \"Miss\"\n",
    "    def transform(self, X, y=None):\n",
    "        X['Titles'] = X.apply(self.get_titles, axis=1)\n",
    "        return X\n",
    "\n",
    "class AgesImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.median_by_titles = X.groupby('Titles')['Age'].median()\n",
    "        self.median_by_gender = X.groupby('Sex')['Age'].median()\n",
    "        self.median_by_pclass = X.groupby('Pclass')['Age'].median()\n",
    "        return self\n",
    "    def estimate_age(self, df):\n",
    "            return pd.Series(data=((self.median_by_titles[df['Titles']].values + self.median_by_gender[df['Sex']].values + self.median_by_pclass[df['Pclass']].values)//3), index=df.index)\n",
    "    def transform(self, X, y=None):\n",
    "        X['Age'].fillna(self.estimate_age(X), axis=0, inplace=True)\n",
    "        return X\n",
    "\n",
    "class TicketNumberAttribute(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def fill_ticket_n(self,row):\n",
    "            import regex as re\n",
    "            try:\n",
    "                return int(re.sub(\"[^0-9]\",\"\",row['Ticket']))\n",
    "            except:\n",
    "                return int(0)\n",
    "    def transform(self, X, y=None):\n",
    "        X['Ticket_n'] = X.apply(self.fill_ticket_n,axis=1)\n",
    "        return X\n",
    "\n",
    "class SurnameFrequencyAttribute(BaseEstimator, TransformerMixin): \n",
    "    def fit(self, X, y = None):\n",
    "        X['Surname'] = X['Name'].apply(lambda x:x.split(', ')[0])\n",
    "        self.surnames_n_repeated = X['Surname'].value_counts()\n",
    "        return self # nothing else to do\n",
    "    def check_surname(self, row):\n",
    "        try:\n",
    "            return self.surnames_n_repeated[row]\n",
    "        except:\n",
    "            return 0\n",
    "    def transform(self, X):\n",
    "        X['Surname'] = X['Name'].apply(lambda x:x.split(', ')[0])\n",
    "        X['Surname_frequency'] = X['Surname'].apply(self.check_surname)\n",
    "        return X\n",
    "\n",
    "class FamilySizeAttribute(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X['Family_size'] = X['SibSp'] + X['Parch'] + 1\n",
    "        X['Family_size_cat'] = X['Family_size'].replace({1:'alone', 2:'small_family', 3:'small_family', 4:'small_family'\n",
    "                                                        ,5:'large_family', 6:'large_family', 7:'large_family'\n",
    "                                                        ,8:'large_family', 9:'large_family', 10:'large_family', \n",
    "                                                        11:'large_family'})\n",
    "        return X\n",
    "\n",
    "class TicketFrequencyAttribute(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X['Ticket_frequency'] =X['Ticket'].map(X['Ticket'].value_counts(dropna=False))\n",
    "        return X\n",
    "\n",
    "class SurvivalRatesAttribute(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.X_temp = pd.concat([X[['Surname','Ticket']],y],axis=1)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X['Family_survival_rate'] = X['Surname'].map(self.X_temp.groupby(['Surname'])['Survived'].median())\n",
    "        X['Ticket_group_survival_rate'] = X['Ticket'].map(self.X_temp.groupby(['Ticket'])['Survived'].median())\n",
    "        return X\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")), # Get rid of possible null values\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", MostFrequentImputer()),\n",
    "    (\"encoder\", OneHotEncoder(drop='first',sparse=False))\n",
    "])\n",
    "\n",
    "combined_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, ['Age','Fare','Ticket_n','Surname_frequency','Ticket_frequency','Family_survival_rate','Ticket_group_survival_rate','Family_size']),\n",
    "    (\"cat\", cat_pipeline, ['Pclass','Sex','Embarked','Titles','Family_size_cat']),\n",
    "])\n",
    "\n",
    "prep_pipeline = Pipeline([\n",
    "    (\"titles\", TitlesAttribute()),\n",
    "    (\"ages_imputer\", AgesImputer()),\n",
    "    (\"ticket_n\", TicketNumberAttribute()),\n",
    "    (\"surname_frequency\", SurnameFrequencyAttribute()),\n",
    "    (\"family_size\", FamilySizeAttribute()),\n",
    "    (\"ticket_frequency\", TicketFrequencyAttribute()),\n",
    "    (\"survival_rates\", SurvivalRatesAttribute()),\n",
    "    (\"combined\", combined_pipeline),\n",
    "])\n",
    "\n",
    "X_train_prep = prep_pipeline.fit_transform(X_train,y_train)\n",
    "X_train_prep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(memory=None,\n         steps=[('classifier',\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=8, max_features='auto',\n                                        max_leaf_nodes=32, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=10, n_jobs=None,\n                                        oob_score=False, random_state=42,\n                                        verbose=0, warm_start=False))],\n         verbose=False)\nThe mean accuracy of the model is: 0.9955106621773289\n"
     ]
    }
   ],
   "source": [
    "## Model building and fine tuning: Grid Search\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def execute_pipeline(features,labels, search_space=[\n",
    "                    {\"classifier\": [LogisticRegression(random_state=42)],\n",
    "                    \"classifier__penalty\": ['l2','l1'],\n",
    "                    \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                    },\n",
    "                    {\"classifier\": [LogisticRegression(random_state=42)],\n",
    "                    \"classifier__penalty\": ['l2'],\n",
    "                    \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                    \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                    },\n",
    "                    {\"classifier\": [RandomForestClassifier(random_state=42)],\n",
    "                    \"classifier__n_estimators\": [10,100,500,1000],\n",
    "                    \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                    \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                    \"classifier__max_leaf_nodes\": [8,16,32]}\n",
    "                 ], \n",
    "                 cv=5, verbose=0, n_jobs=-1):\n",
    "    \n",
    "    pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "    \n",
    "    gridsearch = GridSearchCV(pipe, search_space, cv=cv, verbose=verbose,n_jobs=n_jobs) # Fit grid search\n",
    "    best_model = gridsearch.fit(features, labels)\n",
    "    print(best_model.best_estimator_)\n",
    "    print(\"The mean accuracy of the model is:\",best_model.score(features, labels))\n",
    "\n",
    "    return best_model\n",
    "\n",
    "best_estimator = execute_pipeline(X_train_prep,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6165730337078652\n[[  0 273]\n [  0 439]]\nPrecision:  0.0\nRecall:  0.0\nF1:  0.0\n"
     ]
    }
   ],
   "source": [
    "## Check dummies\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train_prep, y_train)\n",
    "predictions_dummy = dummy_clf.predict(X_train_prep)\n",
    "\n",
    "print(dummy_clf.score(X_train_prep,y_train))\n",
    "print(confusion_matrix(y_train, predictions_dummy,labels=[1,0]))\n",
    "print('Precision: ', precision_score(y_train, predictions_dummy))\n",
    "print('Recall: ', recall_score(y_train, predictions_dummy))\n",
    "print('F1: ', f1_score(y_train, predictions_dummy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "             Pclass                                          Name     Sex  \\\nPassengerId                                                                 \n892               3                              Kelly, Mr. James    male   \n893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n894               2                     Myles, Mr. Thomas Francis    male   \n895               3                              Wirz, Mr. Albert    male   \n896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n...             ...                                           ...     ...   \n1305              3                            Spector, Mr. Woolf    male   \n1306              1                  Oliva y Ocana, Dona. Fermina  female   \n1307              3                  Saether, Mr. Simon Sivertsen    male   \n1308              3                           Ware, Mr. Frederick    male   \n1309              3                      Peter, Master. Michael J    male   \n\n              Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\nPassengerId                                                                    \n892          34.5      0      0              330911    7.8292   NaN        Q   \n893          47.0      1      0              363272    7.0000   NaN        S   \n894          62.0      0      0              240276    9.6875   NaN        Q   \n895          27.0      0      0              315154    8.6625   NaN        S   \n896          22.0      1      1             3101298   12.2875   NaN        S   \n...           ...    ...    ...                 ...       ...   ...      ...   \n1305         27.0      0      0           A.5. 3236    8.0500   NaN        S   \n1306         39.0      0      0            PC 17758  108.9000  C105        C   \n1307         38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S   \n1308         27.0      0      0              359309    8.0500   NaN        S   \n1309         18.0      1      1                2668   22.3583   NaN        C   \n\n             Titles  Ticket_n        Surname  Surname_frequency  Family_size  \\\nPassengerId                                                                    \n892              Mr    330911          Kelly                  4            1   \n893             Mrs    363272         Wilkes                  0            2   \n894              Mr    240276          Myles                  0            1   \n895              Mr    315154           Wirz                  0            1   \n896             Mrs   3101298       Hirvonen                  1            3   \n...             ...       ...            ...                ...          ...   \n1305             Mr     53236        Spector                  0            1   \n1306           Miss     17758  Oliva y Ocana                  0            1   \n1307             Mr   3101262        Saether                  0            1   \n1308             Mr    359309           Ware                  0            1   \n1309         Master      2668          Peter                  2            3   \n\n            Family_size_cat  Ticket_frequency  Family_survival_rate  \\\nPassengerId                                                           \n892                   alone                 1                   1.0   \n893            small_family                 1                   NaN   \n894                   alone                 1                   NaN   \n895                   alone                 1                   NaN   \n896            small_family                 1                   1.0   \n...                     ...               ...                   ...   \n1305                  alone                 1                   NaN   \n1306                  alone                 1                   NaN   \n1307                  alone                 1                   NaN   \n1308                  alone                 1                   NaN   \n1309           small_family                 1                   1.0   \n\n             Ticket_group_survival_rate  Survived  \nPassengerId                                        \n892                                 NaN         0  \n893                                 NaN         0  \n894                                 NaN         0  \n895                                 NaN         0  \n896                                 1.0         1  \n...                                 ...       ...  \n1305                                NaN         0  \n1306                                0.5         1  \n1307                                NaN         0  \n1308                                NaN         0  \n1309                                1.0         1  \n\n[418 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Titles</th>\n      <th>Ticket_n</th>\n      <th>Surname</th>\n      <th>Surname_frequency</th>\n      <th>Family_size</th>\n      <th>Family_size_cat</th>\n      <th>Ticket_frequency</th>\n      <th>Family_survival_rate</th>\n      <th>Ticket_group_survival_rate</th>\n      <th>Survived</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Mr</td>\n      <td>330911</td>\n      <td>Kelly</td>\n      <td>4</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n      <td>363272</td>\n      <td>Wilkes</td>\n      <td>0</td>\n      <td>2</td>\n      <td>small_family</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Mr</td>\n      <td>240276</td>\n      <td>Myles</td>\n      <td>0</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>315154</td>\n      <td>Wirz</td>\n      <td>0</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n      <td>3101298</td>\n      <td>Hirvonen</td>\n      <td>1</td>\n      <td>3</td>\n      <td>small_family</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>3</td>\n      <td>Spector, Mr. Woolf</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A.5. 3236</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>53236</td>\n      <td>Spector</td>\n      <td>0</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>1</td>\n      <td>Oliva y Ocana, Dona. Fermina</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17758</td>\n      <td>108.9000</td>\n      <td>C105</td>\n      <td>C</td>\n      <td>Miss</td>\n      <td>17758</td>\n      <td>Oliva y Ocana</td>\n      <td>0</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>3</td>\n      <td>Saether, Mr. Simon Sivertsen</td>\n      <td>male</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>3101262</td>\n      <td>Saether</td>\n      <td>0</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>3</td>\n      <td>Ware, Mr. Frederick</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>359309</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>359309</td>\n      <td>Ware</td>\n      <td>0</td>\n      <td>1</td>\n      <td>alone</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1309</th>\n      <td>3</td>\n      <td>Peter, Master. Michael J</td>\n      <td>male</td>\n      <td>18.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2668</td>\n      <td>22.3583</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Master</td>\n      <td>2668</td>\n      <td>Peter</td>\n      <td>2</td>\n      <td>3</td>\n      <td>small_family</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 20 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['PassengerId'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-f77f743b88cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\handson-ml2\\my_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\handson-ml2\\my_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\handson-ml2\\my_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PassengerId'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "\n",
    "X_test_prep = prep_pipeline.transform(X_test)\n",
    "X_test['Survived'] = best_estimator.predict(X_test_prep)\n",
    "display(X_test)\n",
    "\n",
    "X_test[['PassengerId','Survived']].to_csv('submission.csv',index=False)"
   ]
  }
 ]
}